{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888fb6c1-998f-4da8-a6ec-e21a7ded926e",
   "metadata": {},
   "source": [
    "## Machine Learning Experiments\n",
    "\n",
    "In this section, we will experiment with various machine learning models to analyze and predict weather patterns based on historical data. We aim to build predictive models that capture trends and relationships in the weather dataset, which may help in forecasting or understanding key factors influencing weather conditions.\n",
    "\n",
    "### Goals\n",
    "1. **Model Selection**: Test different algorithms ( linear regression, KNN ) to identify the most suitable models for weather prediction.\n",
    "2. **Feature Engineering**: Explore ways to transform and optimize features to improve model performance.\n",
    "3. **Hyperparameter Tuning**: Experiment with tuning parameters for each model to achieve the best results.\n",
    "4. **Model Evaluation**: Use appropriate metrics to evaluate and compare model performance, ensuring reliable and interpretable outcomes.\n",
    "\n",
    "Throughout these experiments, we will document our findings, assess each model’s effectiveness, and refine our approach based on performance metrics. The ultimate goal is to establish a model pipeline that consistently performs well on unseen data, making it a reliable tool for weather analysis and prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1cf318c-8454-47bb-97f3-0ffbc3ecc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342e5ff4-cbf0-4243-97dc-c9f1d8fa9890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Precip Type</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Apparent Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Bearing</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.472222</td>\n",
       "      <td>7.388889</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1197</td>\n",
       "      <td>251</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1015.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.355556</td>\n",
       "      <td>7.227778</td>\n",
       "      <td>0.86</td>\n",
       "      <td>14.2646</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1015.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.377778</td>\n",
       "      <td>9.377778</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.9284</td>\n",
       "      <td>204</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1015.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.288889</td>\n",
       "      <td>5.944444</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14.1036</td>\n",
       "      <td>269</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>6.977778</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Summary Precip Type      Temp  Apparent Temp  Humidity  Wind Speed  \\\n",
       "0  Partly Cloudy        rain  9.472222       7.388889      0.89     14.1197   \n",
       "1  Partly Cloudy        rain  9.355556       7.227778      0.86     14.2646   \n",
       "2  Mostly Cloudy        rain  9.377778       9.377778      0.89      3.9284   \n",
       "3  Partly Cloudy        rain  8.288889       5.944444      0.83     14.1036   \n",
       "4  Mostly Cloudy        rain  8.755556       6.977778      0.83     11.0446   \n",
       "\n",
       "   Wind Bearing  Visibility  Pressure  \n",
       "0           251     15.8263   1015.13  \n",
       "1           259     15.8263   1015.63  \n",
       "2           204     14.9569   1015.94  \n",
       "3           269     15.8263   1016.41  \n",
       "4           259     15.8263   1016.51  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the modified version of the dataset\n",
    "df = pd.read_csv('weather_model.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e67c084-c59b-4b30-95ac-ccefc3e9d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying some column names\n",
    "new_column_names = {\n",
    "    'Precip Type': 'Precip_Type',\n",
    "    'Apparent Temp': 'Apparent_Temp',\n",
    "    'Wind Speed': 'Wind_Speed',\n",
    "    'Wind Bearing': 'Wind_Bearing'\n",
    "}\n",
    "\n",
    "df=df.rename(columns=new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc778b76-03ed-46c7-b8c6-4bb96a54916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the values for snow or rain to 0 and 1\n",
    "df['Precip_Type'] = df['Precip_Type'].replace({\n",
    "    'rain': 0,\n",
    "    'snow': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9f4653-868b-4706-882c-189ba6541725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# celeting summary column\n",
    "del df['Summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f582fd8-445d-4f4d-8bbb-aef2fcd13949",
   "metadata": {},
   "source": [
    "## Baseline Expirement \n",
    "- Through getting the average for the temp feature column, We can determine The mean absolute error before trying different algorithms.\n",
    "- This is done to double check the model is it giving better results as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641889fa-e854-4262-8501-1830fbd50623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column for the temp average\n",
    "df['Avg_Temp'] = df['Temp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c215d9b-efe0-48e7-a11f-ce1b5a4238bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for baseline without ML model = 7.94119279385541\n"
     ]
    }
   ],
   "source": [
    "# printing the mean abosulte error to make it as a reference for the model performance\n",
    "print('MAE for baseline without ML model =', mean_absolute_error(df['Temp'], df['Avg_Temp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad1d124-3793-4cef-b100-1c53e87869de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the average column as it is no longer needed\n",
    "del df['Avg_Temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd70588-93e2-46cc-8591-6d531088fcb8",
   "metadata": {},
   "source": [
    "## Splitting Data\n",
    "- In the Below cell, the data will be split into features and label.\n",
    "- The Temp will be the label as we want the model to predict it after all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5920430d-e23f-4b88-b87a-e08e607f36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Temp', axis=1)\n",
    "y = df['Temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1950aaf6-06f9-4886-9cce-4541f7b985d2",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "- Data will be split into train and test\n",
    "- 80 % of the data will be for the train and the rest will be unseen to the model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a599aa34-d6ee-4102-aff1-5c3b41e7751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0993d7-8d49-473e-8bea-160bbcbaf5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Precip_Type', 'Temp', 'Apparent_Temp', 'Humidity', 'Wind_Speed',\n",
       "       'Wind_Bearing', 'Visibility', 'Pressure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating numerical from categorical data\n",
    "df.select_dtypes(['int','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d0e7e3-204e-42e1-a930-e54cb821d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['Apparent_Temp', 'Humidity', 'Wind_Speed', 'Wind_Bearing',\n",
    "       'Visibility', 'Pressure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158c6df-5921-4569-89c6-9162be4af4fb",
   "metadata": {},
   "source": [
    "## Machine Learning Pipeline\r\n",
    "\r\n",
    "This pipeline streamlines the process of preparing data, training models, and evaluating performance. It includes the following steps:\r\n",
    "\r\n",
    "1. **Data Preprocessing**\r\n",
    "   - **Scaling Numerical Features**: The pipeline applies scaling to numerical features to standardize them, which is important for models sensitive to feature magnitudes.\r\n",
    "   - **Encoding Categorical Features**: Categorical variables are encoded to convert them into a suitable format for machine learning models, allowing the pipeline to handle both numerical and categorical data seamlessly.\r\n",
    "\r\n",
    "2. **Cross-Validation**\r\n",
    "   - To ensure robust performance evaluation, we incorporated **cross-validation** rather than a single train-validation-test split. Cross-validation divides the dataset into multiple subsets, or \"folds,\" training the model on different combinations of these folds and averaging the results. \r\n",
    "   - This approach provides a more reliable estimate of model performance across various data subsets, reducing the risk of overfitting or underfitting and ensuring that our model’s performance is consistent and generalizable.\r\n",
    "\r\n",
    "3. **Model Evaluation**\r\n",
    "   - The pipeline evaluates model performance using metrics calculated across cross-validation folds and on the entire dataset.\r\n",
    "   - Metrics used:\r\n",
    "     - **R² Score**: Indicates how well the model explains the variance in the target variable.\r\n",
    "     - **Mean Absolute Error (MAE)**: Measures the average magnitude of prediction errors, providing an intuitive sense of how far off predictions are from actual values.\r\n",
    "\r\n",
    "By wrapping these steps in a function, the pipeline can take any specified model and scaler, making it efficient to test different configurations and quickly assess their performance on the weather dataset. Cross-validation further enhances this process by providing a more comprehensive evaluation of model performance.\r\n",
    "e weather dataset.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c57fe2-9474-4e7b-afa6-0a4a840937fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(model, scaler):\n",
    "    preprocessing=ColumnTransformer(transformers=[\n",
    "        ('scaling', scaler, numerical_features)\n",
    "    ])\n",
    "    \n",
    "    # pipeline step is for applying the preprocssing steps and choosing the model \n",
    "    pipeline=Pipeline(steps=[\n",
    "        ('preprocssing', preprocessing),\n",
    "        ('modeling', model)\n",
    "    ])\n",
    "    \n",
    "    # fitting the model \n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "\n",
    "    result = cross_val_score(pipeline, x_train, y_train)\n",
    "    print(\"\"\"\n",
    "    *Evaluation for the model performance* :\n",
    "    --------------------------------------\"\"\")\n",
    "    print(result)\n",
    "    print('cross val mean =', result.mean())\n",
    "    print('cross val std =', result.std())\n",
    "\n",
    "    \n",
    "    # prediciton for train and test data\n",
    "    train_pred = pipeline.predict(x_train)\n",
    "\n",
    "    # measures for the train data\n",
    "    print(\"\"\"\n",
    "    *Results for the train data* :\n",
    "    ----------------------------\"\"\")\n",
    "    print('r2 score =', r2_score(y_train,train_pred))\n",
    "    print('MAE =', mean_absolute_error(y_train, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd863fb-916b-4219-ba20-548c08cb3117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    *Evaluation for the model performance* :\n",
      "    --------------------------------------\n",
      "[0.99043734 0.99061349 0.99027145 0.99036336 0.99031834]\n",
      "cross val mean = 0.9904007971539798\n",
      "cross val std = 0.0001195845557328748\n",
      "\n",
      "    *Results for the train data* :\n",
      "    ----------------------------\n",
      "r2 score = 0.9904046137832546\n",
      "MAE = 0.7328181269540707\n"
     ]
    }
   ],
   "source": [
    "# EXP 1 (LinearRegression)\n",
    "experiment(Log(r), StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c024442-0bd7-4dc6-b517-4543c108b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    *Evaluation for the model performance* :\n",
      "    --------------------------------------\n",
      "[0.99042488 0.99021604 0.9900409  0.98997099 0.99008898]\n",
      "cross val mean = 0.9901483552262483\n",
      "cross val std = 0.0001597372534250494\n",
      "\n",
      "    *Results for the train data* :\n",
      "    ----------------------------\n",
      "r2 score = 0.9942050296064215\n",
      "MAE = 0.5484878232793082\n"
     ]
    }
   ],
   "source": [
    "# EXP 2 (KNN)\n",
    "experiment(KNeighborsRegressor(), StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80ebfc-3fd7-4036-b663-8de4c7513d73",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "After experimenting with both **linear regression** and **K-Nearest Neighbors**, it was shown that, for the values of the mean absolute error **(MAE)** and **R2 score** (closer to a value of 1 is better), both values are slightly better in **KNN** . Therefore, tuning will be performed for KNN.\n",
    "\r\n",
    "- \r\n",
    "To optimize the **K-Nearest Neighbors (KNN)** model, we will focus on tuning the `n_neighbors` parameter. This controls the number of nearest neighbors used to make predictions:\r\n",
    "\r\n",
    "- **`n_neighbors`**: A smaller value may increase model sensitivity to the local data but risks overfitting, while a larger value provides smoother predictions but may underfit. We will use cross-validation to identify the optimal `n_neighbors` value for the best performance.\r\n",
    "\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06cad9ab-2c83-483f-b801-5432b54e2a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*Results for the test data* :\n",
      "----------------------------\n",
      "r2 score = 0.9913674765998518\n",
      "MAE = 0.666544472060994\n"
     ]
    }
   ],
   "source": [
    "preprocessing=ColumnTransformer(transformers=[\n",
    "    ('scaling', StandardScaler(), numerical_features),\n",
    "])\n",
    "\n",
    "# pipeline step is for applying the preprocssing steps and choosing the model \n",
    "pipeline=Pipeline(steps=[\n",
    "    ('preprocssing', preprocessing),\n",
    "    ('modeling', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# hyperparameter tuning\n",
    "search_space = {\n",
    "    'modeling__n_neighbors': range(5, 22)\n",
    "}\n",
    "\n",
    "\n",
    "# fitting the model \n",
    "grid = GridSearchCV(pipeline, param_grid=search_space)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "train_pred=grid.predict(x_train)\n",
    "test_pred = grid.predict(x_test)\n",
    "print(\"\"\"\n",
    "*Results for the test data* :\n",
    "----------------------------\"\"\")\n",
    "print('r2 score =', r2_score(y_test,test_pred))\n",
    "print('MAE =', mean_absolute_error(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52556aea-a3d0-481e-9293-f55110cab936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modeling__n_neighbors': 6}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "758f586e-9464-482f-b28f-936cf584d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid, open('weather_api.pkl', 'wb'))  # Save as 'weather_api.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eeda7f-e5e6-4159-9783-43b0620820eb",
   "metadata": {},
   "source": [
    "## Model Deployment with Flask\n",
    "\n",
    "In this section, we save the trained model and deploy it as a web service using Flask. This allows us to serve the model and make predictions based on new input data through a REST API.\n",
    "\n",
    "Steps:\n",
    "1. **Save the Model**: The trained model is saved as a pickle file (`weather_api.pkl`) to easily reload it for predictions.\n",
    "2. **Load the Model**: Reload the saved model to ensure it works as expected.\n",
    "3. **Create Flask API**: Using Flask, we set up an endpoint (`/predict`) that accepts POST requests. The API:\n",
    "   - Receives input data in JSON format, processes it, and makes predictions using the loaded model.\n",
    "   - Returns the prediction as JSON, making it simple to integrate with other applications.\n",
    "\n",
    "This deployment approach enables real-time predictions and makes the model accessible to other systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e0aa08-153a-4702-bec6-2c386f35ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(grid, open('weather_api.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fa7bfc6-89b5-4556-8aca-4735e5cc9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('weather_api.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8b612cb-968e-489a-95dc-d3c5e865d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    loaded_model = pickle.load(open('weather_api.pkl', 'rb'))\n",
    "    data=request.get_json(force=True)\n",
    "    print(data)\n",
    "    input_data = {\n",
    "        'Precip_Type' : [int(data['Precip_Type'])],\n",
    "        'Apparent_Temp': [float(data['Apparent_Temp'])],\n",
    "        'Humidity': [float(data['Humidity'])],\n",
    "        'Wind_Speed': [float(data['Wind_Speed'])],\n",
    "        'Wind_Bearing': [float(data['Wind_Bearing'])],\n",
    "        'Visibility': [float(data['Visibility'])],\n",
    "        'Pressure': [float(data['Pressure'])]\n",
    "    }\n",
    "\n",
    "    df=pd.DataFrame(input_data)\n",
    "    prediction=loaded_model.predict(df)\n",
    "\n",
    "    return jsonify({'prediction':prediction.tolist()})\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run(debug=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25e2e6-b415-4ca8-b6b6-ef3829c57f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
